{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import string\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import sklearn.feature_selection as fs\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.cross_validation import KFold, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_ne = \"juri-all-non-empty.csv\"\n",
    "all_e = \"juri.csv\"\n",
    "docs = \"court_rulings_task2_8classes_train.csv\"\n",
    "docs2 = \"court_rulings_task2_6classes_train.csv\"\n",
    "\n",
    "\n",
    "stop = stopwords.words('french')\n",
    "stop.append(u'dun')\n",
    "stop.append(u'dune')\n",
    "stop.append(u'les')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.stemmer = SnowballStemmer(\"french\")\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        return [self.stemmer.stem(t) for t in word_tokenize(doc)]\n",
    "\n",
    "\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return only_ascii\n",
    "\n",
    "\n",
    "def get_preprocessor(suffix=''):\n",
    "    def preprocess(unicode_text):\n",
    "        return unicode_text.strip().lower() + suffix\n",
    "    return preprocess\n",
    "\n",
    "def preprocess_data(X, n, suffix='', binarize=True):\n",
    "    vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1),\n",
    "                                 preprocessor=get_preprocessor(suffix), tokenizer=LemmaTokenizer())\n",
    "    X = vectorizer.fit_transform(X)\n",
    "    X = Binarizer(copy=False).fit_transform(X) if binarize else X\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(filename=all_e):\n",
    "    index, text, rule, area, date, claw = [], [], [], [], [], []\n",
    "    with codecs.open(filename, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            a = line.split(\"\\t\")\n",
    "            if (line != \"\") and (len(a)==7):\n",
    "                idx, loc, dec, dt, dsc, art, law  = line.split(\"\\t\") \n",
    "                if (loc != \"\") and (dsc != \"\") and (dec!=\"\") and (dt!=\"\") and (law!=\"\"):\n",
    "                    index.append(idx)\n",
    "                    area.append(loc)\n",
    "                    rule.append(dec)\n",
    "                    d = str(int(dt.split(\"-\")[0])/10)\n",
    "                    date.append(d)\n",
    "                    text.append(dsc)\n",
    "                    claw.append(law)\n",
    "                \n",
    "    print len(rule), len(text)\n",
    "#     text = np.array(text)\n",
    "#     rule = np.array(rule)\n",
    "    \n",
    "#     rule = reduce_classes(rule)\n",
    "    return index, text, area, date, rule, claw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81006 81006\n"
     ]
    }
   ],
   "source": [
    "idx, X, y_a, y_d, y_r, y_l = load_data(all_ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "# idx, X, y_a, y_d, y_r, y_l, = load_data(all_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data2(fin):\n",
    "    legal, y = [], []\n",
    "    with codecs.open(fin, 'r', encoding=\"utf-8\") as f:\n",
    "        ct = f.read()\n",
    "    ct = ct.split(\"\\n\")\n",
    "    print \"len ct\", len(ct)\n",
    "    for i in range(len(ct)):\n",
    "        aux = ct[i].split(\"\\t\")\n",
    "        if len(aux) == 2:\n",
    "            dsc, dec = aux[0], aux[1]\n",
    "            legal.append(remove_accents(dsc))\n",
    "            y.append(remove_accents(dec))\n",
    "        else:\n",
    "            print i\n",
    "    print len(y), len(legal)\n",
    "    # legal = np.array(legal)\n",
    "    y = np.array(y)\n",
    "    set_y = list(set(y))\n",
    "\n",
    "    for i in range(len(legal)):\n",
    "        legal[i] = legal[i].lower()\n",
    "        legal[i] = ((legal[i].encode(\"utf8\")).translate(None, string.punctuation)).decode(\"utf8\")\n",
    "        legal[i] = ((legal[i].encode(\"utf8\")).translate(None, \"1234567890\")).decode(\"utf8\")\n",
    "        legal[i] = legal[i].replace(\"annule\", \"\")\n",
    "        legal[i] = legal[i].replace(\"casse\", \"\")\n",
    "        legal[i] = legal[i].replace(\"rejeter\", \"\")\n",
    "        legal[i] = legal[i].replace(\"rejette\", \"\")\n",
    "        legal[i] = legal[i].replace(\"irrecevable\", \"\")\n",
    "        legal[i] = legal[i].replace(\"irrecevabilite\", \"\")\n",
    "        legal[i] = legal[i].replace(\"recevable\", \"\")\n",
    "        legal[i] = legal[i].replace(\"recevabilite\", \"\") \n",
    "        legal[i] = legal[i].replace(\"question\", \"\")\n",
    "        legal[i] = legal[i].replace(\"prioritaire\", \"\")\n",
    "    for j in range(len(set_y)):\n",
    "            legal[i] = legal[i].replace(set_y[j], \"\")\n",
    "    # y = reduce_classes(set_y)\n",
    "    print \"reduced classes\", len(set(set_y))\n",
    "    return legal, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len ct 63048\n",
      "63047\n",
      "63047 63047\n",
      "reduced classes 6\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data2(docs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cassation', 'cassation', 'cassation', 'rejet', 'cassation',\n",
       "       'rejet', 'cassation', 'rejet', 'cassation', 'cassation', 'rejet',\n",
       "       'rejet', 'rejet', 'cassation', 'rejet', 'rejet', 'cassation',\n",
       "       'cassation', 'rejet', 'cassation', 'rejet', 'rejet', 'cassation',\n",
       "       'cassation', 'rejet', 'rejet', 'cassation', 'rejet', 'rejet',\n",
       "       'cassation', 'cassation', 'rejet', 'cassation', 'rejet', 'rejet',\n",
       "       'rejet', 'rejet', 'rejet', 'cassation', 'rejet', 'rejet', 'rejet',\n",
       "       'rejet', 'cassation', 'cassation', 'rejet', 'cassation', 'rejet',\n",
       "       'rejet', 'cassation', 'cassation', 'cassation', 'rejet', 'rejet',\n",
       "       'cassation', 'cassation', 'rejet', 'rejet', 'rejet', 'rejet',\n",
       "       'rejet', 'rejet', 'rejet', 'rejet', 'cassation', 'cassation',\n",
       "       'rejet', 'rejet', 'rejet', 'cassation', 'rejet', 'cassation',\n",
       "       'cassation', 'rejet', 'rejet', 'rejet', 'cassation', 'cassation',\n",
       "       'rejet', 'rejet', 'cassation', 'rejet', 'rejet', 'rejet',\n",
       "       'cassation', 'cassation', 'cassation', 'rejet', 'cassation',\n",
       "       'cassation', 'cassation', 'rejet', 'rejet', 'rejet', 'cassation',\n",
       "       'rejet', 'cassation', 'rejet', 'cassation', 'rejet', 'rejet',\n",
       "       'cassation', 'rejet', 'rejet', 'cassation', 'rejet', 'rejet',\n",
       "       'cassation', 'cassation', 'rejet', 'cassation', 'cassation',\n",
       "       'cassation', 'rejet', 'rejet', 'rejet', 'cassation', 'rejet',\n",
       "       'cassation', 'cassation', 'rejet', 'cassation', 'rejet', 'rejet',\n",
       "       'rejet', 'cassation', 'cassation', 'rejet', 'cassation',\n",
       "       'cassation', 'rejet', 'cassation', 'rejet', 'cassation', 'rejet',\n",
       "       'cassation', 'cassation', 'cassation', 'cassation', 'rejet',\n",
       "       'cassation', 'rejet', 'cassation', 'cassation', 'rejet',\n",
       "       'cassation', 'cassation', 'cassation', 'cassation', 'cassation',\n",
       "       'cassation', 'cassation', 'cassation', 'rejet', 'rejet', 'rejet',\n",
       "       'cassation', 'rejet', 'cassation', 'rejet', 'cassation',\n",
       "       'cassation', 'cassation', 'cassation', 'cassation', 'cassation',\n",
       "       'cassation', 'cassation', 'rejet', 'cassation', 'rejet',\n",
       "       'cassation', 'rejet', 'rejet', 'cassation', 'cassation', 'rejet',\n",
       "       'cassation', 'rejet', 'cassation', 'cassation', 'rejet', 'rejet',\n",
       "       'cassation', 'rejet', 'rejet', 'cassation', 'cassation', 'rejet',\n",
       "       'rejet', 'cassation', 'rejet', 'rejet', 'cassation', 'rejet',\n",
       "       'cassation', 'cassation', 'cassation', 'rejet', 'cassation',\n",
       "       'rejet', 'cassation', 'cassation', 'cassation', 'rejet',\n",
       "       'cassation', 'rejet', 'rejet', 'rejet', 'rejet', 'cassation',\n",
       "       'rejet', 'cassation', 'rejet', 'cassation', 'cassation',\n",
       "       'cassation', 'rejet', 'rejet', 'rejet', 'cassation', 'cassation',\n",
       "       'rejet', 'cassation', 'rejet', 'rejet', 'rejet', 'rejet', 'rejet',\n",
       "       'rejet', 'rejet', 'rejet', 'rejet', 'rejet', 'rejet', 'rejet',\n",
       "       'rejet', 'cassation', 'rejet', 'cassation', 'rejet', 'rejet',\n",
       "       'cassation', 'rejet', 'cassation', 'rejet', 'rejet', 'rejet',\n",
       "       'cassation', 'cassation', 'rejet', 'cassation', 'rejet', 'rejet',\n",
       "       'rejet', 'cassation', 'rejet', 'rejet', 'cassation', 'rejet',\n",
       "       'rejet', 'cassation', 'rejet', 'rejet', 'cassation', 'rejet',\n",
       "       'cassation', 'rejet', 'cassation', 'cassation', 'rejet',\n",
       "       'cassation', 'rejet', 'cassation', 'rejet', 'rejet', 'rejet',\n",
       "       'rejet', 'cassation', 'cassation', 'cassation', 'cassation',\n",
       "       'rejet', 'rejet', 'rejet', 'cassation', 'cassation', 'rejet',\n",
       "       'cassation', 'rejet', 'rejet', 'rejet', 'cassation', 'rejet',\n",
       "       'cassation', 'cassation', 'rejet', 'rejet', 'rejet', 'rejet'], \n",
       "      dtype='|S14')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[6000:6300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "2.Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def text_clean_up(text, labels=[], mask=False, mode='ruling', strip=True):\n",
    "    new_text = text\n",
    "    for i in range(len(new_text)):\n",
    "        aux = new_text[i]\n",
    "        if strip == True:\n",
    "            aux = remove_accents(aux)\n",
    "        aux = aux.lower()\n",
    "        aux = ((aux.encode(\"utf8\")).translate(None, string.punctuation)).decode(\"utf8\")\n",
    "        aux = ' '.join(aux.split())\n",
    "        aux = aux.replace(\"non lieu\", \"non-lieu\")\n",
    "        aux = aux.replace(\"nonlieu\", \"non-lieu\")\n",
    "        if mask == True:\n",
    "            if mode == 'ruling':\n",
    "                aux = aux.replace(\"annule\", \"\")\n",
    "                aux = aux.replace(\"annuler\", \"\")\n",
    "                aux = aux.replace(\"casse\", \"\")\n",
    "                aux = aux.replace(\"casser\", \"\")\n",
    "                aux = aux.replace(\"cassant\", \"\")\n",
    "                aux = aux.replace(\"rejeter\", \"\")\n",
    "                aux = aux.replace(\"rejette\", \"\")\n",
    "                aux = aux.replace(\"irrecevable\", \"\")\n",
    "                aux = aux.replace(\"irrecevabilite\", \"\")\n",
    "                aux = aux.replace(\"recevable\", \"\")\n",
    "                aux = aux.replace(\"recevabilite\", \"\")\n",
    "                aux = aux.replace(\"recu\", \"\")\n",
    "#                 if len(labels[i].split()) > 1:\n",
    "#                     l = labels[i].split()\n",
    "#                     for j in range(len(l)):\n",
    "#                         aux = aux.replace(l[j], \"\")\n",
    "#                 else:  \n",
    "                for j in range(len(labels)):\n",
    "                    aux = aux.replace(labels[j], \"\")\n",
    "            elif mode == 'area':\n",
    "                a = (((labels[i].lower().replace(\"_\", \" \")).encode(\"utf8\")).translate(None, \"1234567890\")).decode(\"utf8\")\n",
    "                aux = aux.replace(a, \"\")\n",
    "                a = a.split()\n",
    "                for j in range(len(a)):\n",
    "                    aux.replace(a[j], \"\")\n",
    "            elif mode == 'temp':\n",
    "                aux = ((aux.encode(\"utf8\")).translate(None, \"1234567890\")).decode(\"utf8\")\n",
    "            else: \n",
    "                print \"error: mode unimplemented\"\n",
    "                return     \n",
    "        new_text[i] = aux        \n",
    "    return new_text    \n",
    "\n",
    "def preprocess_classes(y, mode='ruling', setup='mword'):\n",
    "    print \"unique labels:\", len(set(y))\n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        if mode =='ruling':\n",
    "            aux = y[i]\n",
    "            aux = aux.lower()\n",
    "            aux = aux.replace(\"'\", \" \")\n",
    "            aux = aux.replace(\"`\", \" \")\n",
    "            aux = ((aux.encode(\"utf8\")).translate(None, string.punctuation)).decode(\"utf8\")   \n",
    "            aux = ' '.join(aux.split())\n",
    "            aux = aux.replace(\"nonlieu\", \"non-lieu\")\n",
    "            aux = aux.replace(\"non lieu\", \"non-lieu\")\n",
    "            if setup == '1word':\n",
    "                aux = aux.split(\" \")[0]\n",
    "        elif mode == 'area':\n",
    "            aux = y[i]\n",
    "        elif mode == 'temp1':\n",
    "            aux = y[i]\n",
    "            if int(aux) < 196:\n",
    "                aux = '<196'\n",
    "        elif mode == 'temp2':\n",
    "            aux = y[i]\n",
    "            if int(aux) <= 184:\n",
    "                aux = '<=184'\n",
    "            elif int(aux) > 184 and int(aux) <=186:\n",
    "                aux = '185-186'\n",
    "            elif int(aux) > 186 and int(aux) <=188:\n",
    "                aux = '187-188'\n",
    "            elif int(aux) > 188 and int(aux) <=191:\n",
    "                aux = '189-191'\n",
    "            else:\n",
    "                aux = aux\n",
    "        elif mode == 'none':\n",
    "            aux = y[i]\n",
    "        else:\n",
    "            print \"error: mode unimplemented\"\n",
    "            return \n",
    "        new_y.append(aux)\n",
    "    print \"unique labels after initial preprocessing: \", len(set(new_y))\n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = text_clean_up(X,list(set(y)), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_xy(fname):\n",
    "    text, label = [], []\n",
    "    with codecs.open(fname, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            a = line.split(\"\\t\")\n",
    "            if (line != \"\") and (len(a)==2):\n",
    "                text.append(a[0])\n",
    "                label.append(a[1])\n",
    "#     text, label = np.array(text), np.array(label)\n",
    "    return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique labels: 436\n",
      "unique labels after initial preprocessing:  425\n",
      "unique labels: 436\n",
      "unique labels after initial preprocessing:  48\n",
      "unique labels: 17\n",
      "unique labels after initial preprocessing:  17\n",
      "unique labels: 21\n",
      "unique labels after initial preprocessing:  7\n",
      "unique labels: 21\n",
      "unique labels after initial preprocessing:  14\n"
     ]
    }
   ],
   "source": [
    "new_yr = preprocess_classes(y_r, 'ruling')\n",
    "new_Xr = text_clean_up(X, new_yr, True, 'ruling')\n",
    "new_yr2 = preprocess_classes(y_r, 'ruling', '1word')\n",
    "new_Xr2 = text_clean_up(X, new_yr2, True, 'ruling')\n",
    "\n",
    "new_ya = preprocess_classes(y_a, 'area')\n",
    "new_Xa = text_clean_up(X, new_ya, True, 'area')\n",
    "\n",
    "new_yd = preprocess_classes(y_d, 'temp1')\n",
    "new_Xd = text_clean_up(X, new_yd, True, 'temp')\n",
    "new_yd2 = preprocess_classes(y_d, 'temp2')\n",
    "new_Xd2 = text_clean_up(X, new_yd2, True, 'temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Reduce Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label_counts(y):\n",
    "    '''get number of entries (court rulings) \n",
    "    for each label'''\n",
    "    y_s = list(set(y))\n",
    "    idx = np.zeros(len(y_s), dtype=int)\n",
    "    for i in range(len(y)):\n",
    "        for j in range(len(y_s)):\n",
    "            if y[i] == y_s[j]:\n",
    "                idx[j] += 1\n",
    "    return y_s, idx\n",
    "\n",
    "def get_frequent_labels(y, y_rs, idx, threshold=0):\n",
    "    '''get labels that have the number of entries \n",
    "    above threshold'''\n",
    "    count = 0\n",
    "    y_rsr = []\n",
    "    mask_y = np.zeros(len(y), dtype=int)\n",
    "    for i in range(len(idx)):\n",
    "        if idx[i] > threshold:\n",
    "            print y_rs[i], \"&\", idx[i]\n",
    "            y_rsr.append(y_rs[i])\n",
    "            count += idx[i]\n",
    "    print \"number of labels with total entries above \", threshold, \": \", count\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        if y[i] in y_rsr:\n",
    "            mask_y[i] = 1   \n",
    "    return mask_y\n",
    "\n",
    "def reduce_classes(X, y, threshold=0):\n",
    "    new_y, new_X = [], []\n",
    "    print \"initial classes: \", len(set(y))\n",
    "    y_s, idx = get_label_counts(y)\n",
    "    mask = get_frequent_labels(y, y_s, idx, threshold)\n",
    "    for i in range(len(mask)):\n",
    "        if mask[i] == 1:\n",
    "            new_y.append(y[i])\n",
    "            new_X.append(X[i])\n",
    "    print \"classes after reduction: \", len(set(new_y))\n",
    "    return new_X, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial classes:  425\n",
      "cassation partielle & 6771\n",
      "cassation partielle sans renvoi & 869\n",
      "cassation partielle cassation & 960\n",
      "cassation & 27375\n",
      "irrecevabilité & 1585\n",
      "cassation partielle rejet cassation & 798\n",
      "cassation sans renvoi & 1804\n",
      "rejet & 37750\n",
      "number of labels with total entries above  200 :  77912\n",
      "classes after reduction:  8\n",
      "initial classes:  48\n",
      "annulation & 305\n",
      "cassation & 39842\n",
      "rejet & 38209\n",
      "irrecevabilité & 1872\n",
      "number of labels with total entries above  200 :  80228\n",
      "classes after reduction:  4\n",
      "initial classes:  17\n",
      "CHAMBRE_CIVILE_1 & 12194\n",
      "CHAMBRE_CIVILE_2 & 10321\n",
      "CHAMBRE_CIVILE_3 & 10802\n",
      "CHAMBRE_SOCIALE & 20397\n",
      "CHAMBRE_CRIMINELLE & 15317\n",
      "CHAMBRE_COMMERCIALE & 11052\n",
      "ASSEMBLEE_PLENIERE & 391\n",
      "number of labels with total entries above  200 :  80474\n",
      "classes after reduction:  7\n",
      "initial classes:  7\n",
      "201 & 4541\n",
      "200 & 12577\n",
      "199 & 16693\n",
      "198 & 18233\n",
      "197 & 23964\n",
      "196 & 4797\n",
      "<196 & 201\n",
      "number of labels with total entries above  0 :  81006\n",
      "classes after reduction:  7\n",
      "initial classes:  14\n",
      "201 & 4541\n",
      "200 & 12577\n",
      "199 & 16693\n",
      "198 & 18233\n",
      "197 & 23964\n",
      "196 & 4797\n",
      "number of labels with total entries above  1000 :  80805\n",
      "classes after reduction:  6\n"
     ]
    }
   ],
   "source": [
    "new_Xr, new_yr = reduce_classes(new_Xr, new_yr, 200)\n",
    "new_Xr2, new_yr2 = reduce_classes(new_Xr2, new_yr2, 200)\n",
    "new_Xa, new_ya = reduce_classes(new_Xa, new_ya, 200)\n",
    "new_Xd, new_yd = reduce_classes(new_Xd, new_yd)\n",
    "new_Xd2, new_yd2 = reduce_classes(new_Xd2, new_yd2, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainr2_index, testr2_index = next(iter(StratifiedKFold(np.array(new_yr2), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainr_index, testr_index = next(iter(StratifiedKFold(np.array(new_yr), 2)))\n",
    "traina_index, testa_index = next(iter(StratifiedKFold(np.array(new_ya), 2)))\n",
    "traind_index, testd_index = next(iter(StratifiedKFold(np.array(new_yd), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[], [], [], [], trainr_index, testr_index = train_test_split(np.zeros(len(new_Xr)), np.array(new_yr), \n",
    "                                                                               range(len(new_Xr)), test_size=0.30, random_state=42)\n",
    "[], [], [], [], trainr_index, testr_index = train_test_split(np.zeros(len(new_Xr)), np.array(new_ya), \n",
    "                                                                               range(len(new_Xa)), test_size=0.30, random_state=42)\n",
    "[], [], [], [] , trainr_index, testr_index = train_test_split(np.zeros(len(new_Xr)), np.array(new_yd), \n",
    "                                                                               range(len(new_Xd)), test_size=0.30, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fancy_index(x, y, idx):\n",
    "    x_t, y_t = [], []\n",
    "    print \"entered get_fancy_indexing\"\n",
    "    for i in range(len(idx)):\n",
    "        x_t.append(x[idx[i]])\n",
    "        if type(y[idx[i]]) == int:\n",
    "            print i\n",
    "        y_t.append(y[idx[i]])\n",
    "    return x_t, y_t\n",
    "\n",
    "def write_train_test(ftr, fts, x, y, train, test):  \n",
    "    print \"entered write_train_test\"\n",
    "    x_train, y_train = get_fancy_index(x, y, train)\n",
    "    with codecs.open(ftr, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i in range(len(x_train)):\n",
    "            f.write(x_train[i] +\"\\t\" + y_train[i] + \"\\n\")\n",
    "\n",
    "    x_test , y_test = get_fancy_index(x, y, test)\n",
    "    with codecs.open(fts, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i in range(len(x_test)):\n",
    "            f.write(x_test[i] +\"\\t\" + y_test[i] + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered write_train_test\n",
      "entered get_fancy_indexing\n",
      "entered get_fancy_indexing\n"
     ]
    }
   ],
   "source": [
    "write_train_test(\"french_court_rulings_task2_8classes_train.csv\", \"court_rulings_task2_8classes_test.csv\", \n",
    "                 new_Xr2, new_yr2, trainr2_index, testr2_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered write_train_test\n",
      "entered get_fancy_indexing\n",
      "entered get_fancy_indexing\n",
      "entered write_train_test\n",
      "entered get_fancy_indexing\n",
      "entered get_fancy_indexing\n",
      "entered write_train_test\n",
      "entered get_fancy_indexing\n",
      "entered get_fancy_indexing\n"
     ]
    }
   ],
   "source": [
    "write_train_test(\"french_court_rulings_task2_6classes_train.csv\", \"court_rulings_task2_6classes_test.csv\", \n",
    "                 new_Xr, new_yr, trainr_index, testr_index)\n",
    "write_train_test(\"french_court_rulings_task1_8classes_train.csv\", \"court_rulings_task1_8classes_test.csv\", \n",
    "                 new_Xa, new_ya, traina_index, testa_index)\n",
    "write_train_test(\"french_court_rulings_task3_7classes_train.csv\", \"court_rulings_task3_7classes_test.csv\", \n",
    "                 new_Xd, new_yd, traind_index, testd_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "4.Feature Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_best_features(X, y, vectorizer, n):\n",
    "    '''get names of best features in X from vectorizer'''\n",
    "    print \"entered get_best_features\"\n",
    "    f = codecs.open(\"best_k.txt\", \"a\", encoding=\"utf-8\")\n",
    "    fnames = vectorizer.get_feature_names()\n",
    "    b = fs.SelectKBest(fs.f_classif, k=50) #k is number of features.\n",
    "    X_n = b.fit_transform(X, y)\n",
    "    index_v =  b.get_support()\n",
    "\n",
    "    f.write(\"best \"+ n +\"grams:\\n\")\n",
    "    for i in range(len(index_v)):\n",
    "        if index_v[i] == True:\n",
    "            f.write(fnames[i])\n",
    "            f.write(\"\\n\")\n",
    "    f.close()\n",
    "    print \"exited get_best_features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_un = CountVectorizer(analyzer='word', ngram_range=(1, 1))\n",
    "vectorizer_bi = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "vectorizer_tri = CountVectorizer(analyzer='word', ngram_range=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Xr_new = CountVectorizer(analyzer='word', ngram_range=(2, 2)).fit_transform(new_Xr)\n",
    "# Xr_new2 = CountVectorizer(analyzer='word', ngram_range=(2, 2)).fit_transform(new_Xr2)\n",
    "# Xa_new = CountVectorizer(analyzer='word', ngram_range=(2, 2)).fit_transform(new_Xa)\n",
    "# Xd_new = CountVectorizer(analyzer='word', ngram_range=(2, 2)).fit_transform(new_Xd)\n",
    "# Xd_new2 = CountVectorizer(analyzer='word', ngram_range=(2, 2)).fit_transform(new_Xd2)\n",
    "X_new_un = vectorizer_un.fit_transform(X)\n",
    "X_new_bi = vectorizer_bi.fit_transform(X)\n",
    "X_new_tri= vectorizer_tri.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered get_best_features\n",
      "exited get_best_features\n",
      "entered get_best_features\n",
      "exited get_best_features\n",
      "entered get_best_features\n",
      "exited get_best_features\n"
     ]
    }
   ],
   "source": [
    "get_best_features(X_new_un, y, vectorizer_un, \"1\")\n",
    "get_best_features(X_new_bi, y, vectorizer_bi, \"2\")\n",
    "get_best_features(X_new_tri, y, vectorizer_tri, \"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_lexical_density(x):\n",
    "    '''unique tokens/ tokens''' \n",
    "    print \"entered calculate_lexical_density\"\n",
    "    print \"len x\", len(x)\n",
    "    new_x = []\n",
    "    for i in range(len(x)):\n",
    "        unique_w = len(set(x[i].split()))\n",
    "        new_x.append(float(unique_w)/float(len(x[i])))   \n",
    "    print \"type x\", type(new_x)\n",
    "    print \"len new_x\", len(new_x)\n",
    "    new_x = np.array(new_x)\n",
    "    return new_x[:, np.newaxis]\n",
    "    \n",
    "def calculate_lexical_richness(x):\n",
    "    '''unique stems / stems'''\n",
    "    print \"entered calculate_lexical_richness\"\n",
    "    stemmer = SnowballStemmer(\"french\")\n",
    "    new_x = []\n",
    "    for i in range(len(x)):\n",
    "        stems = []\n",
    "        for word in x[i].split():\n",
    "            stems.append(stemmer.stem(word))         \n",
    "        unique_s = len(set(stems))\n",
    "        new_x.append(float(unique_s)/float(len(stems)))\n",
    "    \n",
    "    print \"len new_x:\", len(new_x)\n",
    "    new_x = np.array(new_x)\n",
    "    return new_x[:,np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttr_getter = FunctionTransformer(calculate_lexical_density, validate=False)\n",
    "str_getter = FunctionTransformer(calculate_lexical_richness, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import clone\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_union = FeatureUnion([\n",
    "                            ('type-token-ratio',ttr_getter),\n",
    "#                              ('stem-token-ratio', str_getter),\n",
    "                              ('bow', CountVectorizer(analyzer='word', ngram_range=(2,2)))\n",
    "                             ])\n",
    "\n",
    "\n",
    "\n",
    "clf_pipe = Pipeline([('features', feature_union),\n",
    "                     ('svm',LinearSVC(C=0.1, class_weight='balanced'))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "# X_res, y_res = sm.fit_sample(new_Xd, new_yd)\n",
    "# X_res2, y_res2 = sm.fit_sample(new_Xd2, new_yd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered calculate_lexical_density\n",
      "len x 126865\n",
      "type x <type 'list'>\n",
      "len new_x 126865\n"
     ]
    }
   ],
   "source": [
    "Xd_new = feature_union.fit_transform(new_Xd)\n",
    "Xd_new2 = feature_union.fit_transform(new_Xd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc to vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = doc2vec.Doc2Vec.load(\"court-task1-8_test.d2v2\")\n",
    "model2_tr = doc2vec.Doc2Vec.load(\"court-task2-8_train.d2v2\")\n",
    "# model2_ts = doc2vec.Doc2Vec.load(\"court-task2-8_test.d2v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_docvecs_np(vecs):\n",
    "    np_vecs = np.zeros((len(vecs), len(vecs[0])), dtype=vecs[0].dtype)\n",
    "    for i in range(len(vecs)):\n",
    "        np_vecs[i] = vecs[i]\n",
    "    print \"types\", type(np_vecs)\n",
    "    return np_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "types <type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_new_d2v = get_docvecs_np(model2_tr.docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61358"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_new_d2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "5.Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_val(X, y, clf, dummy, cv, mode='np'):\n",
    "    accuracy, recall, precision, f1 = [], [], [], []\n",
    "    dummy_acc, dummy_rec, dummy_prec, dummy_f1 = [], [], [], []\n",
    "    print \"-------------\"\n",
    "    print \"entered cross_val\"\n",
    "    \n",
    "    for train_index, test_index in cv:\n",
    "        if mode == 'list':\n",
    "            X_train, y_train = get_fancy_index(X, y, train_index)\n",
    "            X_test, y_test = get_fancy_index(X, y, test_index)\n",
    "            y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "        \n",
    "        elif mode == 'np':   \n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "        else:\n",
    "            print \"error: unimplemented mode\"\n",
    "            \n",
    "        print \"fitting the classifier\"\n",
    "        clf.fit(X_train, y_train)\n",
    "        dummy.fit(X_train, y_train)\n",
    "\n",
    "        print \"predicting\"\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_dummy = dummy.predict(X_test)\n",
    "        \n",
    "        print \"type test pred\", type(y_test), type(y_pred), len(y_test), len(y_pred), y_pred.shape, y_test.shape\n",
    "\n",
    "        print \"svm report:\\n\", classification_report(y_test, y_pred)\n",
    "        print \"dummy report: \\n\", classification_report(y_test, y_dummy)\n",
    "\n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        precision.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recall.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        f1.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "        dummy_acc.append(accuracy_score(y_test, y_dummy))\n",
    "        dummy_prec.append(precision_score(y_test, y_dummy, average='weighted'))\n",
    "        dummy_rec.append(recall_score(y_test, y_dummy, average='weighted'))\n",
    "        dummy_f1.append(f1_score(y_test, y_dummy, average='weighted'))\n",
    "        print \"accuracy mean \", np.mean(accuracy), \" accuracy std \", np.std(accuracy)\n",
    "        \n",
    "    print \"precision mean \", np.mean(precision), \" and std \", np.std(precision)\n",
    "    print \"recall mean \", np.mean(recall), \" and std \", np.std(recall)\n",
    "    print \"f1 mean \", np.mean(f1), \" and std \", np.std(f1)\n",
    "    print \"dummy accuracy mean \", np.mean(dummy_acc), \" accuracy std \", np.std(dummy_acc)\n",
    "    print \"dummy precision mean \", np.mean(dummy_rec), \" and std \", np.std(dummy_prec)\n",
    "    print \"dummy recall mean \", np.mean(dummy_rec), \" and std \", np.std(dummy_rec)\n",
    "    print \"dummy f1 mean \", np.mean(dummy_f1), \" and std \", np.std(dummy_f1)\n",
    "    print \"------------\"\n",
    "    print \"exited cross_val\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# skf_r = StratifiedKFold(new_yr, n_folds=10)\n",
    "# skf_r2 = StratifiedKFold(new_yr2, n_folds=10)\n",
    "# skf_a = StratifiedKFold(new_ya, n_folds=10)\n",
    "# skf_d = StratifiedKFold(new_yd, n_folds=10)\n",
    "# skf_d2 = StratifiedKFold(new_yd2, n_folds=10)\n",
    "skf_d2v = StratifiedKFold(y, n_folds=10)\n",
    "# clf = LinearSVC(C=0.01, class_weight='balanced')\n",
    "clf = KNeighborsClassifier(n_neighbors=8)\n",
    "dummy = DummyClassifier(strategy=\"stratified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "entered cross_val\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 6139 6139 (6139L,) (6139L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.30      0.56      0.39      1883\n",
      "cassation partielle       0.05      0.00      0.00       478\n",
      "cassation partielle cassation       1.00      0.03      0.07        59\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        46\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        51\n",
      "cassation sans renvoi       0.00      0.00      0.00       104\n",
      "irrecevabilite       0.07      0.50      0.12       119\n",
      "      rejet       0.54      0.27      0.36      3399\n",
      "\n",
      "avg / total       0.41      0.33      0.32      6139\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.31      0.30      0.30      1883\n",
      "cassation partielle       0.09      0.09      0.09       478\n",
      "cassation partielle cassation       0.00      0.00      0.00        59\n",
      "cassation partielle rejet cassation       0.02      0.02      0.02        46\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        51\n",
      "cassation sans renvoi       0.02      0.02      0.02       104\n",
      "irrecevabilite       0.01      0.01      0.01       119\n",
      "      rejet       0.54      0.55      0.55      3399\n",
      "\n",
      "avg / total       0.40      0.40      0.40      6139\n",
      "\n",
      "accuracy mean  0.329858283108  accuracy std  0.0\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 6137 6137 (6137L,) (6137L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.31      0.60      0.41      1883\n",
      "cassation partielle       0.31      0.13      0.19       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        46\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        51\n",
      "cassation sans renvoi       0.00      0.00      0.00       104\n",
      "irrecevabilite       0.09      0.39      0.15       119\n",
      "      rejet       0.50      0.26      0.34      3399\n",
      "\n",
      "avg / total       0.40      0.34      0.33      6137\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.30      0.30      0.30      1883\n",
      "cassation partielle       0.09      0.09      0.09       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        46\n",
      "cassation partielle sans renvoi       0.02      0.02      0.02        51\n",
      "cassation sans renvoi       0.00      0.00      0.00       104\n",
      "irrecevabilite       0.02      0.03      0.02       119\n",
      "      rejet       0.56      0.56      0.56      3399\n",
      "\n",
      "avg / total       0.41      0.41      0.41      6137\n",
      "\n",
      "accuracy mean  0.337244605136  accuracy std  0.00738632202756\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 6137 6137 (6137L,) (6137L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.28      0.46      0.35      1883\n",
      "cassation partielle       0.09      0.01      0.01       477\n",
      "cassation partielle cassation       0.16      0.05      0.08        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        46\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        51\n",
      "cassation sans renvoi       0.00      0.00      0.00       104\n",
      "irrecevabilite       0.09      0.48      0.15       119\n",
      "      rejet       0.55      0.38      0.45      3399\n",
      "\n",
      "avg / total       0.40      0.36      0.36      6137\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.30      0.30      0.30      1883\n",
      "cassation partielle       0.06      0.06      0.06       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.03      0.02      0.02        46\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        51\n",
      "cassation sans renvoi       0.01      0.01      0.01       104\n",
      "irrecevabilite       0.00      0.00      0.00       119\n",
      "      rejet       0.55      0.55      0.55      3399\n",
      "\n",
      "avg / total       0.40      0.40      0.40      6137\n",
      "\n",
      "accuracy mean  0.345844347588  accuracy std  0.0135750865882\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 6136 6136 (6136L,) (6136L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.26      0.41      0.31      1883\n",
      "cassation partielle       0.30      0.01      0.01       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        45\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        51\n",
      "cassation sans renvoi       0.14      0.01      0.02       104\n",
      "irrecevabilite       0.08      0.50      0.14       119\n",
      "      rejet       0.51      0.36      0.42      3399\n",
      "\n",
      "avg / total       0.39      0.33      0.33      6136\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.30      0.30      0.30      1883\n",
      "cassation partielle       0.06      0.07      0.06       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        45\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        51\n",
      "cassation sans renvoi       0.04      0.05      0.05       104\n",
      "irrecevabilite       0.03      0.03      0.03       119\n",
      "      rejet       0.55      0.54      0.54      3399\n",
      "\n",
      "avg / total       0.40      0.40      0.40      6136\n",
      "\n",
      "accuracy mean  0.342703012972  accuracy std  0.0129543884998\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 6136 6136 (6136L,) (6136L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.33      0.51      0.40      1883\n",
      "cassation partielle       0.06      0.01      0.01       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        45\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        51\n",
      "cassation sans renvoi       0.06      0.01      0.02       104\n",
      "irrecevabilite       0.11      0.60      0.19       119\n",
      "      rejet       0.59      0.43      0.50      3399\n",
      "\n",
      "avg / total       0.43      0.41      0.40      6136\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.31      0.31      0.31      1883\n",
      "cassation partielle       0.08      0.08      0.08       477\n",
      "cassation partielle cassation       0.02      0.02      0.02        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        45\n",
      "cassation partielle sans renvoi       0.02      0.02      0.02        51\n",
      "cassation sans renvoi       0.01      0.01      0.01       104\n",
      "irrecevabilite       0.02      0.02      0.02       119\n",
      "      rejet       0.55      0.55      0.55      3399\n",
      "\n",
      "avg / total       0.41      0.41      0.41      6136\n",
      "\n",
      "accuracy mean  0.355616126154  accuracy std  0.0283063051855\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 6136 6136 (6136L,) (6136L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.32      0.64      0.43      1883\n",
      "cassation partielle       0.23      0.01      0.01       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        45\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        51\n",
      "cassation sans renvoi       0.00      0.00      0.00       104\n",
      "irrecevabilite       0.11      0.52      0.18       119\n",
      "      rejet       0.58      0.30      0.39      3399\n",
      "\n",
      "avg / total       0.44      0.37      0.35      6136\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.30      0.30      0.30      1883\n",
      "cassation partielle       0.08      0.08      0.08       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        45\n",
      "cassation partielle sans renvoi       0.02      0.02      0.02        51\n",
      "cassation sans renvoi       0.04      0.04      0.04       104\n",
      "irrecevabilite       0.02      0.02      0.02       119\n",
      "      rejet       0.55      0.55      0.55      3399\n",
      "\n",
      "avg / total       0.41      0.40      0.41      6136\n",
      "\n",
      "accuracy mean  0.358466502347  accuracy std  0.0266144506472\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 6136 6136 (6136L,) (6136L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.31      0.59      0.41      1883\n",
      "cassation partielle       0.22      0.00      0.01       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        45\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        51\n",
      "cassation sans renvoi       0.00      0.00      0.00       104\n",
      "irrecevabilite       0.10      0.55      0.17       119\n",
      "      rejet       0.61      0.34      0.44      3399\n",
      "\n",
      "avg / total       0.45      0.38      0.37      6136\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.32      0.31      0.31      1883\n",
      "cassation partielle       0.07      0.07      0.07       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.03      0.02      0.02        45\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        51\n",
      "cassation sans renvoi       0.00      0.00      0.00       104\n",
      "irrecevabilite       0.01      0.01      0.01       119\n",
      "      rejet       0.56      0.57      0.56      3399\n",
      "\n",
      "avg / total       0.41      0.42      0.41      6136\n",
      "\n",
      "accuracy mean  0.361689857292  accuracy std  0.025874296727\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 6135 6135 (6135L,) (6135L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.30      0.59      0.40      1883\n",
      "cassation partielle       0.12      0.00      0.00       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        45\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        50\n",
      "cassation sans renvoi       0.00      0.00      0.00       104\n",
      "irrecevabilite       0.09      0.83      0.17       119\n",
      "      rejet       0.61      0.24      0.35      3399\n",
      "\n",
      "avg / total       0.44      0.33      0.32      6135\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.32      0.33      0.33      1883\n",
      "cassation partielle       0.11      0.10      0.11       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        45\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        50\n",
      "cassation sans renvoi       0.02      0.02      0.02       104\n",
      "irrecevabilite       0.04      0.03      0.03       119\n",
      "      rejet       0.56      0.56      0.56      3399\n",
      "\n",
      "avg / total       0.42      0.42      0.42      6135\n",
      "\n",
      "accuracy mean  0.358165666695  accuracy std  0.0259371116888\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 6134 6134 (6134L,) (6134L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.30      0.57      0.39      1883\n",
      "cassation partielle       0.19      0.05      0.08       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        45\n",
      "cassation partielle sans renvoi       0.00      0.00      0.00        50\n",
      "cassation sans renvoi       0.00      0.00      0.00       104\n",
      "irrecevabilite       0.12      0.66      0.21       118\n",
      "      rejet       0.56      0.29      0.38      3399\n",
      "\n",
      "avg / total       0.42      0.35      0.34      6134\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.31      0.32      0.31      1883\n",
      "cassation partielle       0.07      0.07      0.07       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        45\n",
      "cassation partielle sans renvoi       0.02      0.02      0.02        50\n",
      "cassation sans renvoi       0.01      0.01      0.01       104\n",
      "irrecevabilite       0.02      0.02      0.02       118\n",
      "      rejet       0.55      0.55      0.55      3399\n",
      "\n",
      "avg / total       0.41      0.41      0.41      6134\n",
      "\n",
      "accuracy mean  0.357550005363  accuracy std  0.024515665969\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 6132 6132 (6132L,) (6132L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.34      0.59      0.43      1882\n",
      "cassation partielle       0.26      0.12      0.17       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        45\n",
      "cassation partielle sans renvoi       0.03      0.02      0.02        50\n",
      "cassation sans renvoi       0.00      0.00      0.00       103\n",
      "irrecevabilite       0.16      0.66      0.26       118\n",
      "      rejet       0.57      0.36      0.44      3399\n",
      "\n",
      "avg / total       0.45      0.40      0.40      6132\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  cassation       0.31      0.30      0.31      1882\n",
      "cassation partielle       0.07      0.07      0.07       477\n",
      "cassation partielle cassation       0.00      0.00      0.00        58\n",
      "cassation partielle rejet cassation       0.00      0.00      0.00        45\n",
      "cassation partielle sans renvoi       0.04      0.04      0.04        50\n",
      "cassation sans renvoi       0.04      0.04      0.04       103\n",
      "irrecevabilite       0.01      0.01      0.01       118\n",
      "      rejet       0.56      0.58      0.57      3399\n",
      "\n",
      "avg / total       0.42      0.42      0.42      6132\n",
      "\n",
      "accuracy mean  0.362140732159  accuracy std  0.0270294106989\n",
      "precision mean  0.422770100756  and std  0.021529617971\n",
      "recall mean  0.362140732159  and std  0.0270294106989\n",
      "f1 mean  0.353075246385  and std  0.0281990168909\n",
      "dummy accuracy mean  0.408423873614  accuracy std  0.00734780353399\n",
      "dummy precision mean  0.408423873614  and std  0.00591208764319\n",
      "dummy recall mean  0.408423873614  and std  0.00734780353399\n",
      "dummy f1 mean  0.408199901335  and std  0.00650301045997\n",
      "------------\n",
      "exited cross_val\n"
     ]
    }
   ],
   "source": [
    "cross_val(X_new_d2v, y, clf, dummy, skf_d2v, 'np')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begining of Minidemo\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train  = load_data_xy(\"court_rulings_task2_6classes_train.csv\")\n",
    "X_test, y_test = load_data_xy(\"court_rulings_task2_6classes_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_new = CountVectorizer(analyzer='word', ngram_range=(2, 2)).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_new = X_new[:len(X_train)]\n",
    "X_test_new = X_new[len(X_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train_new, y_train)\n",
    "y_pred = clf.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'cassation\\n',\n",
       " u'cassation\\n',\n",
       " u'sur le moyen unique attendu que dame z reproche a l arret confirmatif attaque paris  novembre  de l avoir declaree personnellement en liquidation des biens par application de l article  de la loi du  juillet  alors selon le pourvoi que les simples actes de gestion et d administration ainsi que la seule qualite de dirigeant de fait de la societe quot internationale d application des techniques electriques mecaniques pneumatiques et connexes quot sinatnem ne suffisent pas a justifier l extension a dame michel de y des biens de cette societe qu en l espece la cour d appel n a pas releve un acte quelconque effectue par le dirigeant dans son interet personnel ni aucun fait precis revelant qu il avait dispose des biens sociaux comme des siens propres et qu elle n a pas plus indique les circonstances de fait susceptibles de faire apparaitre que la poursuite de l exploitation etait abusive ou dictee par le seul interet du dirigeant qu en definitive la cour d appel ne pouvait fonder sa decision par des affirmations de caractere general et en se bornant a reproduire les formules de la loi sans preciser en fait en quoi les agissements du dirigeant justifiaient dans ce cas precis l application de telles formules et notamment sans rechercher si le dirigeant avait agi dans son seul interet personnel mais attendu que la cour d appel a par une decision dument motivee releve souverainement que la sinatnem n etait qu une societe de facade derriere laquelle dame z faisait personnellement le commerce que des lors elle a pu faire application a ladite dame de x  de la loi du  juillet  que le moyen n est pas fonde par ces motifs le pourvoi forme contre l arret rendu le  novembre  par la cour d appel de paris')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[30], y_test[30], X[30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Minidemo\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_yd2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "entered cross_val\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 12659 12659 (12659L,) (12659L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.76      0.98      0.86      3243\n",
      "        197       0.54      0.62      0.58      2675\n",
      "        198       0.50      0.38      0.43      2363\n",
      "        199       0.71      0.59      0.64      2067\n",
      "        200       0.82      0.74      0.78      1679\n",
      "        201       1.00      0.56      0.72       632\n",
      "\n",
      "avg / total       0.68      0.68      0.67     12659\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.26      0.26      0.26      3243\n",
      "        197       0.21      0.21      0.21      2675\n",
      "        198       0.18      0.18      0.18      2363\n",
      "        199       0.17      0.17      0.17      2067\n",
      "        200       0.12      0.12      0.12      1679\n",
      "        201       0.04      0.04      0.04       632\n",
      "\n",
      "avg / total       0.19      0.19      0.19     12659\n",
      "\n",
      "accuracy mean  0.675882771151  accuracy std  0.0\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 12659 12659 (12659L,) (12659L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.90      0.96      0.93      3243\n",
      "        197       0.90      0.85      0.87      2675\n",
      "        198       0.80      0.84      0.82      2363\n",
      "        199       0.86      0.78      0.81      2067\n",
      "        200       0.94      0.99      0.96      1679\n",
      "        201       1.00      0.81      0.90       632\n",
      "\n",
      "avg / total       0.88      0.88      0.88     12659\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.26      0.26      0.26      3243\n",
      "        197       0.21      0.21      0.21      2675\n",
      "        198       0.19      0.19      0.19      2363\n",
      "        199       0.17      0.17      0.17      2067\n",
      "        200       0.14      0.13      0.14      1679\n",
      "        201       0.05      0.05      0.05       632\n",
      "\n",
      "avg / total       0.19      0.19      0.19     12659\n",
      "\n",
      "accuracy mean  0.77837901888  accuracy std  0.102496247729\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 12659 12659 (12659L,) (12659L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.97      0.95      0.96      3243\n",
      "        197       0.93      0.94      0.94      2675\n",
      "        198       0.83      0.51      0.63      2363\n",
      "        199       0.61      0.90      0.73      2067\n",
      "        200       0.93      0.98      0.95      1679\n",
      "        201       1.00      0.79      0.88       632\n",
      "\n",
      "avg / total       0.87      0.85      0.85     12659\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.26      0.27      0.26      3243\n",
      "        197       0.20      0.20      0.20      2675\n",
      "        198       0.20      0.19      0.20      2363\n",
      "        199       0.15      0.15      0.15      2067\n",
      "        200       0.13      0.13      0.13      1679\n",
      "        201       0.05      0.05      0.05       632\n",
      "\n",
      "avg / total       0.19      0.19      0.19     12659\n",
      "\n",
      "accuracy mean  0.803854964847  accuracy std  0.0911136735706\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 12658 12658 (12658L,) (12658L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.97      0.98      0.97      3243\n",
      "        197       0.80      0.81      0.81      2675\n",
      "        198       0.61      0.40      0.48      2362\n",
      "        199       0.65      0.90      0.76      2067\n",
      "        200       0.94      0.98      0.96      1679\n",
      "        201       0.96      0.85      0.90       632\n",
      "\n",
      "avg / total       0.81      0.82      0.81     12658\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.26      0.26      0.26      3243\n",
      "        197       0.22      0.22      0.22      2675\n",
      "        198       0.18      0.18      0.18      2362\n",
      "        199       0.18      0.18      0.18      2067\n",
      "        200       0.11      0.11      0.11      1679\n",
      "        201       0.06      0.06      0.06       632\n",
      "\n",
      "avg / total       0.19      0.19      0.19     12658\n",
      "\n",
      "accuracy mean  0.806774143528  accuracy std  0.0790685838128\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 12657 12657 (12657L,) (12657L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.71      0.44      0.54      3243\n",
      "        197       0.50      0.70      0.58      2674\n",
      "        198       0.73      0.59      0.65      2362\n",
      "        199       0.63      0.78      0.70      2067\n",
      "        200       0.73      0.52      0.61      1679\n",
      "        201       0.39      0.81      0.53       632\n",
      "\n",
      "avg / total       0.64      0.61      0.60     12657\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.25      0.25      0.25      3243\n",
      "        197       0.22      0.23      0.22      2674\n",
      "        198       0.19      0.19      0.19      2362\n",
      "        199       0.17      0.17      0.17      2067\n",
      "        200       0.14      0.13      0.14      1679\n",
      "        201       0.05      0.05      0.05       632\n",
      "\n",
      "avg / total       0.19      0.19      0.19     12657\n",
      "\n",
      "accuracy mean  0.766522261808  accuracy std  0.10715562834\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 12657 12657 (12657L,) (12657L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.94      0.94      0.94      3243\n",
      "        197       0.75      0.78      0.77      2674\n",
      "        198       0.60      0.60      0.60      2362\n",
      "        199       0.63      0.74      0.68      2067\n",
      "        200       0.90      0.66      0.76      1679\n",
      "        201       0.79      0.79      0.79       632\n",
      "\n",
      "avg / total       0.77      0.77      0.77     12657\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.25      0.25      0.25      3243\n",
      "        197       0.21      0.21      0.21      2674\n",
      "        198       0.19      0.19      0.19      2362\n",
      "        199       0.16      0.15      0.16      2067\n",
      "        200       0.15      0.15      0.15      1679\n",
      "        201       0.05      0.05      0.05       632\n",
      "\n",
      "avg / total       0.19      0.19      0.19     12657\n",
      "\n",
      "accuracy mean  0.766273752845  accuracy std  0.097820836333\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 12656 12656 (12656L,) (12656L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.93      0.76      0.83      3243\n",
      "        197       0.60      0.68      0.64      2674\n",
      "        198       0.58      0.58      0.58      2362\n",
      "        199       0.61      0.77      0.68      2067\n",
      "        200       0.77      0.67      0.72      1679\n",
      "        201       0.66      0.61      0.63       631\n",
      "\n",
      "avg / total       0.71      0.69      0.69     12656\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.25      0.26      0.26      3243\n",
      "        197       0.23      0.22      0.23      2674\n",
      "        198       0.19      0.20      0.19      2362\n",
      "        199       0.17      0.17      0.17      2067\n",
      "        200       0.14      0.13      0.13      1679\n",
      "        201       0.05      0.05      0.05       631\n",
      "\n",
      "avg / total       0.20      0.20      0.20     12656\n",
      "\n",
      "accuracy mean  0.75537027831  accuracy std  0.0944205621648\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 12655 12655 (12655L,) (12655L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.81      0.95      0.87      3243\n",
      "        197       0.59      0.73      0.65      2674\n",
      "        198       0.69      0.49      0.57      2362\n",
      "        199       0.93      0.66      0.78      2067\n",
      "        200       0.79      0.53      0.64      1678\n",
      "        201       0.45      0.92      0.61       631\n",
      "\n",
      "avg / total       0.74      0.71      0.71     12655\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.25      0.26      0.26      3243\n",
      "        197       0.21      0.21      0.21      2674\n",
      "        198       0.19      0.19      0.19      2362\n",
      "        199       0.17      0.17      0.17      2067\n",
      "        200       0.13      0.12      0.13      1678\n",
      "        201       0.03      0.03      0.03       631\n",
      "\n",
      "avg / total       0.19      0.19      0.19     12655\n",
      "\n",
      "accuracy mean  0.749945437614  accuracy std  0.0894809449859\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 12654 12654 (12654L,) (12654L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.98      0.99      0.98      3243\n",
      "        197       0.97      0.88      0.92      2674\n",
      "        198       0.63      0.94      0.76      2362\n",
      "        199       0.74      0.51      0.60      2066\n",
      "        200       0.86      0.79      0.83      1678\n",
      "        201       0.83      0.64      0.72       631\n",
      "\n",
      "avg / total       0.85      0.83      0.83     12654\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.27      0.26      0.26      3243\n",
      "        197       0.21      0.21      0.21      2674\n",
      "        198       0.19      0.19      0.19      2362\n",
      "        199       0.16      0.17      0.17      2066\n",
      "        200       0.14      0.14      0.14      1678\n",
      "        201       0.07      0.07      0.07       631\n",
      "\n",
      "avg / total       0.20      0.20      0.20     12654\n",
      "\n",
      "accuracy mean  0.759219540071  accuracy std  0.0883473966316\n",
      "fitting the classifier\n",
      "predicting\n",
      "type test pred <type 'numpy.ndarray'> <type 'numpy.ndarray'> 12654 12654 (12654L,) (12654L,)\n",
      "svm report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.99      0.64      0.78      3243\n",
      "        197       0.64      0.75      0.69      2674\n",
      "        198       0.54      0.44      0.48      2362\n",
      "        199       0.57      0.86      0.69      2066\n",
      "        200       0.92      0.73      0.81      1678\n",
      "        201       0.58      0.96      0.72       631\n",
      "\n",
      "avg / total       0.73      0.69      0.69     12654\n",
      "\n",
      "dummy report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        196       0.25      0.25      0.25      3243\n",
      "        197       0.21      0.21      0.21      2674\n",
      "        198       0.18      0.18      0.18      2362\n",
      "        199       0.16      0.17      0.17      2066\n",
      "        200       0.12      0.12      0.12      1678\n",
      "        201       0.04      0.04      0.04       631\n",
      "\n",
      "avg / total       0.19      0.19      0.19     12654\n",
      "\n",
      "accuracy mean  0.752382460412  accuracy std  0.086287004623\n",
      "precision mean  0.769316742229  and std  0.0785499723832\n",
      "recall mean  0.752382460412  and std  0.086287004623\n",
      "f1 mean  0.750061638809  and std  0.0857994876011\n",
      "dummy accuracy mean  0.192726419701  accuracy std  0.00327242188651\n",
      "dummy precision mean  0.192726419701  and std  0.00327318858154\n",
      "dummy recall mean  0.192726419701  and std  0.00327242188651\n",
      "dummy f1 mean  0.192581493469  and std  0.00326130400886\n",
      "------------\n",
      "exited cross_val\n"
     ]
    }
   ],
   "source": [
    "# cross_val(Xr_new, np.array(new_yr), clf, dummy, skf_r)\n",
    "# cross_val(Xr_new2, np.array(new_yr2), clf, dummy, skf_r2)\n",
    "# cross_val(Xa_new, np.array(new_ya), clf, dummy, skf_a)\n",
    "# cross_val(Xd_new, np.array(new_yd), clf, dummy, skf_d)\n",
    "cross_val(Xd_new2, np.array(new_yd2), clf, dummy, skf_d2)\n",
    "# cross_val(new_Xd, np.array(new_yd), clf_pipe, dummy, skf_d, mode='list')\n",
    "# cross_val(new_Xd2, np.array(new_yd2), clf_pipe, dummy, skf_d2, mode='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({1: 500, -1: 268})\n",
      "Resampled dataset shape Counter({1: 500, -1: 500})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pima = fetch_mldata('diabetes_scale')\n",
    "X, y = pima['data'], pima['target']\n",
    "print('Original dataset shape {}'.format(Counter(y)))\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_sample(X, y)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "7.Get best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_features(X, y, vectorizer):\n",
    "    '''get names of best features in X from vectorizer'''\n",
    "    print \"entered get_best_features\"\n",
    "    f = codecs.open(\"results.txt\", \"w\", encoding=\"utf-8\")\n",
    "    fnames = vectorizer.get_feature_names()\n",
    "    b = fs.SelectKBest(fs.f_classif, k=50) #k is number of features.\n",
    "    X_n = b.fit_transform(X, y)\n",
    "    index_v =  b.get_support()\n",
    "\n",
    "    print \"best unigrams:\"\n",
    "    for i in range(len(index_v)):\n",
    "        if index_v[i] == True:\n",
    "            f.write(fnames[i])\n",
    "            f.write(\"\\n\")\n",
    "    f.close()\n",
    "    print \"exited get_best_features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "8.Significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-bcabd76ddb87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermutation_scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermutation_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_significance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_Xr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_yr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Author:  Alexandre Gramfort <alexandre.gramfort@inria.fr>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import StratifiedKFold, permutation_test_score\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "svm = LinearSVC(C=0.1)\n",
    "cv = StratifiedKFold(new_yr, 10)\n",
    "\n",
    "def get_significance(clf, X, y, cv):\n",
    "    score, permutation_scores, pvalue = permutation_test_score(\n",
    "        svm, X, y, scoring=\"f1\", cv=cv, n_permutations=100, n_jobs=1)\n",
    "\n",
    "    print(\"Classification score %s (pvalue : %s)\" % (score, pvalue))\n",
    "    return score, permutation_scores\n",
    "\n",
    "score, permutation_scores, pvalue = get_significance(svm, new_Xr, np.array(new_yr), cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score, permutation_scores, pvalue = get_significance(svm, new_Xr, new_yr, cv)\n",
    "n_classes = len(set(new_yr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# View histogram of permutation scores\n",
    "plt.hist(permutation_scores, 20, label='Permutation scores')\n",
    "ylim = plt.ylim()\n",
    "# BUG: vlines(..., linestyle='--') fails on older versions of matplotlib\n",
    "#plt.vlines(score, ylim[0], ylim[1], linestyle='--',\n",
    "#          color='g', linewidth=3, label='Classification Score'\n",
    "#          ' (pvalue %s)' % pvalue)\n",
    "#plt.vlines(1.0 / n_classes, ylim[0], ylim[1], linestyle='--',\n",
    "#          color='k', linewidth=3, label='Luck')\n",
    "plt.plot(2 * [score], ylim, '--g', linewidth=3,\n",
    "         label='Classification Score'\n",
    "         ' (pvalue %s)' % pvalue)\n",
    "plt.plot(2 * [1. / n_classes], ylim, '--k', linewidth=3, label='Luck')\n",
    "\n",
    "plt.ylim(ylim)\n",
    "plt.legend()\n",
    "plt.xlabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2Get True Ruling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_rule_dct(y):\n",
    "    '''get vocabulary of rulings \n",
    "    from ruling labels'''\n",
    "    y_set = list(set(y))\n",
    "    print \"unique ruling labels\", len(y_set)\n",
    "    dct = []\n",
    "    for i in range(len(y_set)):\n",
    "        aux = y_set[i].split()\n",
    "        for j in range(len(aux)):\n",
    "            if aux[j] not in dct and aux[j] not in stop:\n",
    "                dct.append(aux[j])\n",
    "    print \"unique words in ruling labels\", len(set(dct))\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique ruling labels 414\n",
      "unique words in ruling labels 142\n"
     ]
    }
   ],
   "source": [
    "r_dct = get_rule_dct(new_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# r_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_label_from_text(X, dct, split_char=' '):\n",
    "    '''attempt to get label from text by \n",
    "    matching label with first word of the text'''\n",
    "    new_y = []\n",
    "    for i in range(len(X)):\n",
    "        aux = X[i].split(split_char)[0]\n",
    "#         print aux\n",
    "        if aux in dct:\n",
    "            new_y.append(aux)\n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_y = split_text(X, r_dct, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_y_set = list(set(new_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10819, 28, 81006)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_y), len(new_y_set), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new_y_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "Train test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, u'CHAMBRE_CIVILE')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index[0], yl[train_index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokens = []\n",
    "with open(\"court_rulings_task2_8classes_train.csv\") as f:\n",
    "    for line in f:\n",
    "        tokens = (gensim.utils.to_unicode(line).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'la',\n",
       " u'cour',\n",
       " u'de',\n",
       " u'cassation',\n",
       " u'a',\n",
       " u'rendu',\n",
       " u'l',\n",
       " u'arret',\n",
       " u'suivant',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'vu',\n",
       " u'la',\n",
       " u'connexite',\n",
       " u'joint',\n",
       " u'les',\n",
       " u'pourvois',\n",
       " u'n',\n",
       " u't',\n",
       " u'z',\n",
       " u'a',\n",
       " u'et',\n",
       " u'b',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'attendu',\n",
       " u'selon',\n",
       " u'les',\n",
       " u'arrets',\n",
       " u'attaques',\n",
       " u'aix',\n",
       " u'en',\n",
       " u'provence',\n",
       " u'septembre',\n",
       " u'que',\n",
       " u'm',\n",
       " u'x',\n",
       " u'm',\n",
       " u'y',\n",
       " u'm',\n",
       " u'z',\n",
       " u'et',\n",
       " u'm',\n",
       " u'a',\n",
       " u'ont',\n",
       " u'ete',\n",
       " u'engages',\n",
       " u'avant',\n",
       " u'le',\n",
       " u'er',\n",
       " u'juin',\n",
       " u'par',\n",
       " u'la',\n",
       " u'societe',\n",
       " u'carrefour',\n",
       " u'france',\n",
       " u'aux',\n",
       " u'droits',\n",
       " u'de',\n",
       " u'laquelle',\n",
       " u'se',\n",
       " u'trouve',\n",
       " u'la',\n",
       " u'societe',\n",
       " u'carrefour',\n",
       " u'hypermaches',\n",
       " u'en',\n",
       " u'qualite',\n",
       " u'de',\n",
       " u'vendeurs',\n",
       " u'qualifies',\n",
       " u'des',\n",
       " u'rayons',\n",
       " u'informatique',\n",
       " u'electromenager',\n",
       " u'gros',\n",
       " u'et',\n",
       " u'petit',\n",
       " u'photographie',\n",
       " u'cinema',\n",
       " u'et',\n",
       " u'son',\n",
       " u'soit',\n",
       " u'vendeurs',\n",
       " u'epcs',\n",
       " u'qu',\n",
       " u'un',\n",
       " u'accord',\n",
       " u'd',\n",
       " u'entreprise',\n",
       " u'concernant',\n",
       " u'la',\n",
       " u'classification',\n",
       " u'des',\n",
       " u'salaries',\n",
       " u'le',\n",
       " u'temps',\n",
       " u'de',\n",
       " u'travail',\n",
       " u'et',\n",
       " u'les',\n",
       " u'modalites',\n",
       " u'de',\n",
       " u'remuneration',\n",
       " u'a',\n",
       " u'ete',\n",
       " u'signe',\n",
       " u'le',\n",
       " u'mars',\n",
       " u'que',\n",
       " u'ce',\n",
       " u'texte',\n",
       " u'a',\n",
       " u'ete',\n",
       " u'modifie',\n",
       " u'par',\n",
       " u'un',\n",
       " u'avenant',\n",
       " u'du',\n",
       " u'mars',\n",
       " u'concernant',\n",
       " u'les',\n",
       " u'vendeurs',\n",
       " u'epcs',\n",
       " u'que',\n",
       " u'les',\n",
       " u'salaries',\n",
       " u'ont',\n",
       " u'saisi',\n",
       " u'la',\n",
       " u'juridiction',\n",
       " u'prud',\n",
       " u'homale',\n",
       " u'en',\n",
       " u'demandant',\n",
       " u'le',\n",
       " u'paiement',\n",
       " u'de',\n",
       " u'rappel',\n",
       " u'de',\n",
       " u'salaires',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'sur',\n",
       " u'le',\n",
       " u'premier',\n",
       " u'moyen',\n",
       " u'pris',\n",
       " u'en',\n",
       " u'sa',\n",
       " u'premiere',\n",
       " u'branche',\n",
       " u'qui',\n",
       " u'est',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'attendu',\n",
       " u'que',\n",
       " u'les',\n",
       " u'salaries',\n",
       " u'font',\n",
       " u'grief',\n",
       " u'aux',\n",
       " u'arrets',\n",
       " u'de',\n",
       " u'les',\n",
       " u'debouter',\n",
       " u'de',\n",
       " u'leurs',\n",
       " u'demandes',\n",
       " u'de',\n",
       " u'salaires',\n",
       " u'alors',\n",
       " u'selon',\n",
       " u'le',\n",
       " u'moyen',\n",
       " u'qu',\n",
       " u'aux',\n",
       " u'termes',\n",
       " u'des',\n",
       " u'titres',\n",
       " u'bis',\n",
       " u'bis',\n",
       " u'et',\n",
       " u'ter',\n",
       " u'de',\n",
       " u'l',\n",
       " u'accord',\n",
       " u'd',\n",
       " u'entreprise',\n",
       " u'carrefour',\n",
       " u'du',\n",
       " u'mars',\n",
       " u'chaque',\n",
       " u'salarie',\n",
       " u'percoit',\n",
       " u'une',\n",
       " u'indemnite',\n",
       " u'dite',\n",
       " u'compensatrice',\n",
       " u'destinee',\n",
       " u'a',\n",
       " u'neutraliser',\n",
       " u'la',\n",
       " u'suppression',\n",
       " u'de',\n",
       " u'la',\n",
       " u'prime',\n",
       " u'd',\n",
       " u'anciennete',\n",
       " u'et',\n",
       " u'de',\n",
       " u'la',\n",
       " u'prime',\n",
       " u'de',\n",
       " u'presence',\n",
       " u'par',\n",
       " u'ailleurs',\n",
       " u'decidees',\n",
       " u'par',\n",
       " u'l',\n",
       " u'accord',\n",
       " u'que',\n",
       " u's',\n",
       " u'agissant',\n",
       " u'des',\n",
       " u'vendeurs',\n",
       " u'qualifies',\n",
       " u'de',\n",
       " u'produits',\n",
       " u'et',\n",
       " u'de',\n",
       " u'services',\n",
       " u'egalement',\n",
       " u'denommes',\n",
       " u'vendeurs',\n",
       " u'epcs',\n",
       " u'il',\n",
       " u'resulte',\n",
       " u'du',\n",
       " u'titre',\n",
       " u'bis',\n",
       " u'de',\n",
       " u'cet',\n",
       " u'accord',\n",
       " u'dans',\n",
       " u'sa',\n",
       " u'redaction',\n",
       " u'issue',\n",
       " u'de',\n",
       " u'l',\n",
       " u'avenant',\n",
       " u'de',\n",
       " u'revision',\n",
       " u'du',\n",
       " u'mars',\n",
       " u'que',\n",
       " u'chaque',\n",
       " u'salarie',\n",
       " u'de',\n",
       " u'cette',\n",
       " u'categorie',\n",
       " u'percoit',\n",
       " u'outre',\n",
       " u'l',\n",
       " u'indemnite',\n",
       " u'precitee',\n",
       " u'une',\n",
       " u'seconde',\n",
       " u'indemnite',\n",
       " u'compensatrice',\n",
       " u'celle',\n",
       " u'ci',\n",
       " u'etant',\n",
       " u'dite',\n",
       " u'specifique',\n",
       " u'destinee',\n",
       " u'a',\n",
       " u'neutraliser',\n",
       " u'la',\n",
       " u'baisse',\n",
       " u'du',\n",
       " u'salaire',\n",
       " u'de',\n",
       " u'base',\n",
       " u'et',\n",
       " u'la',\n",
       " u'reduction',\n",
       " u'de',\n",
       " u'la',\n",
       " u'duree',\n",
       " u'hebdomadaire',\n",
       " u'de',\n",
       " u'travail',\n",
       " u'que',\n",
       " u'selon',\n",
       " u'ces',\n",
       " u'memes',\n",
       " u'dispositions',\n",
       " u'chaque',\n",
       " u'vendeur',\n",
       " u'qualifie',\n",
       " u'de',\n",
       " u'produits',\n",
       " u'et',\n",
       " u'de',\n",
       " u'services',\n",
       " u'percoit',\n",
       " u'egalement',\n",
       " u'outre',\n",
       " u'son',\n",
       " u'salaire',\n",
       " u'de',\n",
       " u'base',\n",
       " u'une',\n",
       " u'part',\n",
       " u'de',\n",
       " u'remuneration',\n",
       " u'variable',\n",
       " u'calculee',\n",
       " u'apres',\n",
       " u'deduction',\n",
       " u'de',\n",
       " u'l',\n",
       " u'indemnite',\n",
       " u'compensatrice',\n",
       " u'le',\n",
       " u'salarie',\n",
       " u'ne',\n",
       " u'pouvant',\n",
       " u'percevoir',\n",
       " u'une',\n",
       " u'somme',\n",
       " u'inferieure',\n",
       " u'au',\n",
       " u'montant',\n",
       " u'de',\n",
       " u'cette',\n",
       " u'derniere',\n",
       " u'qu',\n",
       " u'il',\n",
       " u'resulte',\n",
       " u'de',\n",
       " u'la',\n",
       " u'combinaison',\n",
       " u'de',\n",
       " u'ces',\n",
       " u'dispositions',\n",
       " u'que',\n",
       " u'l',\n",
       " u'indemnite',\n",
       " u'devant',\n",
       " u'venir',\n",
       " u'en',\n",
       " u'deduction',\n",
       " u'de',\n",
       " u'la',\n",
       " u'part',\n",
       " u'variable',\n",
       " u'de',\n",
       " u'remuneration',\n",
       " u'des',\n",
       " u'vendeurs',\n",
       " u'qualifies',\n",
       " u'de',\n",
       " u'produits',\n",
       " u'et',\n",
       " u'de',\n",
       " u'services',\n",
       " u'est',\n",
       " u'l',\n",
       " u'indemnite',\n",
       " u'compensatrice',\n",
       " u'prevue',\n",
       " u'par',\n",
       " u'les',\n",
       " u'titres',\n",
       " u'bis',\n",
       " u'bis',\n",
       " u'et',\n",
       " u'ter',\n",
       " u'de',\n",
       " u'l',\n",
       " u'accord',\n",
       " u'd',\n",
       " u'entreprise',\n",
       " u'faute',\n",
       " u'pour',\n",
       " u'les',\n",
       " u'signataires',\n",
       " u'du',\n",
       " u'texte',\n",
       " u'conventionnel',\n",
       " u'd',\n",
       " u'avoir',\n",
       " u'precise',\n",
       " u'que',\n",
       " u'la',\n",
       " u'partie',\n",
       " u'variable',\n",
       " u'serait',\n",
       " u'calculee',\n",
       " u'par',\n",
       " u'reference',\n",
       " u'a',\n",
       " u'l',\n",
       " u'indemnite',\n",
       " u'compensatrice',\n",
       " u'specifique',\n",
       " u'que',\n",
       " u'le',\n",
       " u'titre',\n",
       " u'bis',\n",
       " u'de',\n",
       " u'l',\n",
       " u'accord',\n",
       " u'institue',\n",
       " u'qu',\n",
       " u'en',\n",
       " u'jugeant',\n",
       " u'du',\n",
       " u'contraire',\n",
       " u'pour',\n",
       " u'debouter',\n",
       " u'les',\n",
       " u'salaries',\n",
       " u'de',\n",
       " u'leurs',\n",
       " u'demandes',\n",
       " u'de',\n",
       " u'rappel',\n",
       " u'de',\n",
       " u'salaire',\n",
       " u'la',\n",
       " u'cour',\n",
       " u'd',\n",
       " u'appel',\n",
       " u'a',\n",
       " u'viole',\n",
       " u'les',\n",
       " u'dispositions',\n",
       " u'conventionnelles',\n",
       " u'susvisees',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'mais',\n",
       " u'attendu',\n",
       " u'qu',\n",
       " u'ayant',\n",
       " u'releve',\n",
       " u'que',\n",
       " u'l',\n",
       " u'avenant',\n",
       " u'de',\n",
       " u'l',\n",
       " u'article',\n",
       " u'bis',\n",
       " u'de',\n",
       " u'l',\n",
       " u'accord',\n",
       " u'd',\n",
       " u'entreprise',\n",
       " u'du',\n",
       " u'mars',\n",
       " u'dans',\n",
       " u'sa',\n",
       " u'version',\n",
       " u'actualisee',\n",
       " u'a',\n",
       " u'la',\n",
       " u'suite',\n",
       " u'de',\n",
       " u'l',\n",
       " u'avenant',\n",
       " u'du',\n",
       " u'mars',\n",
       " u'etait',\n",
       " u'ainsi',\n",
       " u'redige',\n",
       " u'ainsi',\n",
       " u'a',\n",
       " u'titre',\n",
       " u'transitoire',\n",
       " u'du',\n",
       " u'er',\n",
       " u'juin',\n",
       " u'au',\n",
       " u'mai',\n",
       " u'la',\n",
       " u'remuneration',\n",
       " u'mensuelle',\n",
       " u'des',\n",
       " u'vendeurs',\n",
       " u'de',\n",
       " u'produits',\n",
       " u'et',\n",
       " u'de',\n",
       " u'services',\n",
       " u'est',\n",
       " u'constituee',\n",
       " u'd',\n",
       " u'une',\n",
       " u'partie',\n",
       " u'fixe',\n",
       " u'correspondant',\n",
       " u'au',\n",
       " u'salaire',\n",
       " u'de',\n",
       " u'base',\n",
       " u'du',\n",
       " u'niveau',\n",
       " u'iii',\n",
       " u'de',\n",
       " u'la',\n",
       " u'grille',\n",
       " u'des',\n",
       " u'salaires',\n",
       " u'applicables',\n",
       " u'au',\n",
       " u'magasin',\n",
       " u'considere',\n",
       " u'd',\n",
       " u'une',\n",
       " u'partie',\n",
       " u'variable',\n",
       " u'liee',\n",
       " u'a',\n",
       " u'la',\n",
       " u'realisation',\n",
       " u'des',\n",
       " u'objectifs',\n",
       " u'fixes',\n",
       " u'dont',\n",
       " u'le',\n",
       " u'montant',\n",
       " u'maximum',\n",
       " u's',\n",
       " u'etablit',\n",
       " u'a',\n",
       " u'fr',\n",
       " u'bruts',\n",
       " u'cette',\n",
       " u'partie',\n",
       " u'variable',\n",
       " u'devra',\n",
       " u'remunerer',\n",
       " u'd',\n",
       " u'une',\n",
       " u'part',\n",
       " u'les',\n",
       " u'performances',\n",
       " u'de',\n",
       " u'chaque',\n",
       " u'rayon',\n",
       " u'd',\n",
       " u'autre',\n",
       " u'part',\n",
       " u'les',\n",
       " u'performances',\n",
       " u'de',\n",
       " u'chaque',\n",
       " u'vendeur',\n",
       " u'les',\n",
       " u'vendeurs',\n",
       " u'de',\n",
       " u'produits',\n",
       " u'et',\n",
       " u'de',\n",
       " u'services',\n",
       " u'dont',\n",
       " u'le',\n",
       " u'salaire',\n",
       " u'mensuel',\n",
       " u'de',\n",
       " u'base',\n",
       " u'est',\n",
       " u'superieur',\n",
       " u'a',\n",
       " u'la',\n",
       " u'partie',\n",
       " u'fixe',\n",
       " u'telle',\n",
       " u'que',\n",
       " u'prevue',\n",
       " u'a',\n",
       " u'l',\n",
       " u'alinea',\n",
       " u'precedent',\n",
       " u'a',\n",
       " u'la',\n",
       " u'date',\n",
       " u'd',\n",
       " u'application',\n",
       " u'de',\n",
       " u'l',\n",
       " u'accord',\n",
       " u'et',\n",
       " u'a',\n",
       " u'l',\n",
       " u'article',\n",
       " u'du',\n",
       " u'titre',\n",
       " u'a',\n",
       " u'la',\n",
       " u'date',\n",
       " u'du',\n",
       " u'er',\n",
       " u'juin',\n",
       " u'se',\n",
       " u'verront',\n",
       " u'maintenir',\n",
       " u'leur',\n",
       " u'remuneration',\n",
       " u'par',\n",
       " u'l',\n",
       " u'adjonction',\n",
       " u'd',\n",
       " u'une',\n",
       " u'indemnite',\n",
       " u'compensatrice',\n",
       " u'specifique',\n",
       " u'a',\n",
       " u'compter',\n",
       " u'du',\n",
       " u'er',\n",
       " u'juin',\n",
       " u'si',\n",
       " u'la',\n",
       " u'performance',\n",
       " u'individuelle',\n",
       " u'et',\n",
       " u'collective',\n",
       " u'peut',\n",
       " u'permettre',\n",
       " u'l',\n",
       " u'octroi',\n",
       " u'au',\n",
       " u'salarie',\n",
       " u'd',\n",
       " u'une',\n",
       " u'partie',\n",
       " u'variable',\n",
       " u'd',\n",
       " u'un',\n",
       " u'montant',\n",
       " u'superieur',\n",
       " u'au',\n",
       " u'montant',\n",
       " u'de',\n",
       " u'l',\n",
       " u'indemnite',\n",
       " u'compensatrice',\n",
       " u'il',\n",
       " u'percevra',\n",
       " u'une',\n",
       " u'partie',\n",
       " u'variable',\n",
       " u'equivalente',\n",
       " u'a',\n",
       " u'la',\n",
       " u'difference',\n",
       " u'entre',\n",
       " u'ces',\n",
       " u'deux',\n",
       " u'montants',\n",
       " u'a',\n",
       " u'compter',\n",
       " u'du',\n",
       " u'er',\n",
       " u'juin',\n",
       " u'si',\n",
       " u'la',\n",
       " u'performance',\n",
       " u'individuelle',\n",
       " u'et',\n",
       " u'collective',\n",
       " u'est',\n",
       " u'insuffisante',\n",
       " u'pour',\n",
       " u'permettre',\n",
       " u'au',\n",
       " u'salarie',\n",
       " u'l',\n",
       " u'octroi',\n",
       " u'd',\n",
       " u'une',\n",
       " u'partie',\n",
       " u'variable',\n",
       " u'd',\n",
       " u'un',\n",
       " u'montant',\n",
       " u'superieur',\n",
       " u'au',\n",
       " u'montant',\n",
       " u'de',\n",
       " u'l',\n",
       " u'indemnite',\n",
       " u'compensatrice',\n",
       " u'il',\n",
       " u'ne',\n",
       " u'percevra',\n",
       " u'pas',\n",
       " u'de',\n",
       " u'partie',\n",
       " u'variable',\n",
       " u'la',\n",
       " u'cour',\n",
       " u'd',\n",
       " u'appel',\n",
       " u'qui',\n",
       " u'a',\n",
       " u'constate',\n",
       " u'que',\n",
       " u'la',\n",
       " u'specificite',\n",
       " u'du',\n",
       " u'statut',\n",
       " u'des',\n",
       " u'vendeurs',\n",
       " u'epcs',\n",
       " u'ne',\n",
       " u'serait',\n",
       " u'plus',\n",
       " u'prise',\n",
       " u'en',\n",
       " u'compte',\n",
       " u'si',\n",
       " u'l',\n",
       " u'indemnite',\n",
       " u'compensatrice',\n",
       " u'dont',\n",
       " u'il',\n",
       " u'est',\n",
       " u'question',\n",
       " u'dans',\n",
       " u'ce',\n",
       " u'texte',\n",
       " u's',\n",
       " u'analysait',\n",
       " u'comme',\n",
       " u'correspondant',\n",
       " u'a',\n",
       " u'l',\n",
       " u'indemnite',\n",
       " u'compensatrice',\n",
       " u'destinee',\n",
       " u'a',\n",
       " u'compenser',\n",
       " u'la',\n",
       " u'suppression',\n",
       " u'des',\n",
       " u'primes',\n",
       " u'de',\n",
       " u'presence',\n",
       " u'et',\n",
       " u'd',\n",
       " u'anciennete',\n",
       " u'prevue',\n",
       " u'aux',\n",
       " u'articles',\n",
       " u'bis',\n",
       " u'bis',\n",
       " u'et',\n",
       " u'ter',\n",
       " u'de',\n",
       " u'l',\n",
       " u'accord',\n",
       " u'a',\n",
       " u'fait',\n",
       " u'une',\n",
       " u'exacte',\n",
       " u'application',\n",
       " u'de',\n",
       " u'l',\n",
       " u'article',\n",
       " u'bis',\n",
       " u'de',\n",
       " u'l',\n",
       " u'accord',\n",
       " u'collectif',\n",
       " u'que',\n",
       " u'le',\n",
       " u'moyen',\n",
       " u'n',\n",
       " u'est',\n",
       " u'pas',\n",
       " u'fonde',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'sur',\n",
       " u'le',\n",
       " u'premier',\n",
       " u'moyen',\n",
       " u'pris',\n",
       " u'en',\n",
       " u'sa',\n",
       " u'seconde',\n",
       " u'branche',\n",
       " u'et',\n",
       " u'sur',\n",
       " u'le',\n",
       " u'second',\n",
       " u'moyen',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'attendu',\n",
       " u'qu',\n",
       " u'il',\n",
       " u'n',\n",
       " u'y',\n",
       " u'a',\n",
       " u'pas',\n",
       " u'lieu',\n",
       " u'de',\n",
       " u'statuer',\n",
       " u'par',\n",
       " u'une',\n",
       " u'decision',\n",
       " u'specialement',\n",
       " u'motivee',\n",
       " u'sur',\n",
       " u'les',\n",
       " u'moyens',\n",
       " u'annexes',\n",
       " u'qui',\n",
       " u'ne',\n",
       " u'sont',\n",
       " u'manifestement',\n",
       " u'pas',\n",
       " u'de',\n",
       " u'nature',\n",
       " u'a',\n",
       " u'entrainer',\n",
       " u'la',\n",
       " u'cassation',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'par',\n",
       " u'ces',\n",
       " u'motifs',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'les',\n",
       " u'pourvois',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'condamne',\n",
       " u'mm',\n",
       " u'x',\n",
       " u'y',\n",
       " u'z',\n",
       " u'et',\n",
       " u'a',\n",
       " u'aux',\n",
       " u'depens',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'vu',\n",
       " u'l',\n",
       " u'article',\n",
       " u'du',\n",
       " u'code',\n",
       " u'de',\n",
       " u'procedure',\n",
       " u'civile',\n",
       " u'les',\n",
       " u'demandes',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'ainsi',\n",
       " u'fait',\n",
       " u'et',\n",
       " u'juge',\n",
       " u'par',\n",
       " u'la',\n",
       " u'cour',\n",
       " u'de',\n",
       " u'cassation',\n",
       " u'et',\n",
       " u'prononce',\n",
       " u'par',\n",
       " u'le',\n",
       " u'president',\n",
       " u'en',\n",
       " u'son',\n",
       " u'audience',\n",
       " u'publique',\n",
       " u'du',\n",
       " u'sept',\n",
       " u'juillet',\n",
       " u'deux',\n",
       " u'mille',\n",
       " u'quinze',\n",
       " u'moyens',\n",
       " u'annexes',\n",
       " u'au',\n",
       " u'present',\n",
       " u'arret',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'moyens',\n",
       " u'communs',\n",
       " u'produits',\n",
       " u'aux',\n",
       " u'pourvois',\n",
       " u'par',\n",
       " u'la',\n",
       " u'scp',\n",
       " u'masse',\n",
       " u'dessen',\n",
       " u'thouvenin',\n",
       " u'et',\n",
       " u'coudray',\n",
       " u'avocat',\n",
       " u'aux',\n",
       " u'conseils',\n",
       " u'pour',\n",
       " u'mm',\n",
       " u'x',\n",
       " u'y',\n",
       " u'z',\n",
       " u'et',\n",
       " u'a',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'premier',\n",
       " u'moyen',\n",
       " u'de',\n",
       " u'cassation',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'br',\n",
       " u'clear',\n",
       " u'none',\n",
       " u'le',\n",
       " u'moyen',\n",
       " u'reproche',\n",
       " u'aux',\n",
       " u'arrets',\n",
       " u'infirmatifs',\n",
       " u'attaques',\n",
       " u'd',\n",
       " u'avoir',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
